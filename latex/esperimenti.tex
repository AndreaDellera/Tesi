\section{Esperimenti}
TODO: introduzione dei grafici di train\_error e validation\_error
\subsection{Esperimento 1 - Imparare sequenze di note semplici}
Prima di descrivere l'esperimento \`e necessario dare alcune informazioni sulla rete:
\begin{itemize}
\item[-]sono state utilizzate cinque note per comporre l'input;
\item[-]il numero di neuroni nell'hidden layer \`e pari a venti.
\end{itemize}
La FNN impara sequenze pi\`u semplici di note pi\`u velocemente e pi\`u correttamente rispetto a quella ricorrente. Dalle prove fatte (arpeggi sulla tonalit\`a di do maggio re e scala su due ottave di do maggiore) la FFN \`e stata capace di ricondursi pi\`u velocemente alle sequenze imparate. La RNN invece impara con errori le sequenze, risultato che contribuisce a non saper ricreare correttamente gli esempi.
\\
Nel primo file le sequenze di note erano disposte in una forma a cerchio\footnote{pu\`o non sembra un cerchio ma rispetta il \emph{ciclo delle quinte}, una progressione di note in cui ad ognuna viene fatta seguire la sua quinta naturale}.

\begin{center}
      \includegraphics[width=0.7\textwidth]{img/ciclo}
\end{center}
Gli errori medi ottenuti in fase di train e validazione sono:
\begin{table}[ht]
\centering
\begin{tabular}{| c | c | c |}
\multicolumn {3}{c}{\textbf{Errori esempio a cerchio}}\\
\hline
&\textbf{FFN}&\textbf{RNN}\\\hline
Allenamento&0.153463&0.003124\\\hline
Validazione&0.306923&0.027443\\\hline
\end{tabular}
\end{table}\\
L'andamento durante le tutte le sessioni di allenamento degli errori di addestramento (in blu) e di validazione (in verde) \`e:
\begin{table}[ht]
\centering
\begin{tabular}{| c | c |}
\multicolumn {2}{c}{\textbf{Progressione errori esempio a cerchio}}\\
\hline
\textbf{FFN}&\textbf{RNN}\\\hline
\includegraphics[width=0.4\textwidth]{img/ffn_circle_errors.png}
&
\includegraphics[width=0.4\textwidth]{img/rnn_circle_errors.png}
\\\hline
\end{tabular}
\end{table}\\
Nonostante gli errori nella RNN fossero pi\`u bassi quando si trattava di generare delle note la FFN riusciva a ricreare le stesse esatte sequenze mentre la RNN dopo un certo numero di note generate cominciava a perdere coerenza con quanto gi\`a creato. Questo \`e dovuto al fatto che un errore in una RNN influenza per molto tempo l'output della rete mentre nella FFN l'errore sparisce una volta che la nota esce dall'input. Inoltre si vede chiaramente come la FFN si blocchi in un minimo locale senza riuscire ad uscirne.
\\\\Nel secondo file invece le note erano disposte come a formare una figura ad otto. 
\begin{center}
      \includegraphics[width=0.7\textwidth]{img/eight.png}
\end{center}
Di seguito sono riportati gli errori medi ottenuti in fase di addestramento, in fase di validazione e l'andamento lungo tutte le sessioni di allenamento degli errori di addestramento (in blu) e di validazione (in verde).
\\I grafici presentati presentano in dettaglio l'inizio dell'addestramento visto che poi tendono a zero. L'andamento degli errori nell FFN indica che probabilmente i dati sono soggetti a rumore, non si spiega altrimenti il comportamento oscillatorio.
\begin{table}[ht]
\centering
\begin{tabular}{| c | c | c |}
\multicolumn {3}{c}{\textbf{Errori esempio a otto}}\\
\hline
&\textbf{FFN}&\textbf{RNN}\\\hline
Allenamento&0.000759&0.002412\\\hline
Validazione&0.001569&0.006690\\\hline
\end{tabular}
\end{table}
\begin{table}[ht]
\centering
\begin{tabular}{| c | c |}
\multicolumn {2}{c}{\textbf{Progressione errori esempio a otto}}\\
\hline
\textbf{FFN}&\textbf{RNN}\\\hline
\includegraphics[width=0.4\textwidth]{img/ffn_eight.png}
&
\includegraphics[width=0.4\textwidth]{img/rnn_eight.png}
\\\hline
\end{tabular}
\end{table}

\subsection{Esperimento 2 - Imparare una canzone}
Quando si \`e trattato di fare imparare sequenze di note derivate da una canzone il processo di apprendimento \`e risultato molto pi\`u complesso ed infatti sono stati fatti degli accorgimenti alla rete:
\begin{itemize}
\item[-]sono state aumentate le note in input, da cinque ad otto;
\item[-]\`e stato aumentato il numero di neuroni nell'hidden layer, da venti a cinquanta.
\end{itemize}
Questo perch\`e le sequenze di note erano maggiori in numero rispetto all'esperimento precedente ma anche perch\`e erano molto pi\`u varie. La RNN si \`e dimostrata pi\`u difficile da allenare, ha richiesto un numero maggiore di epochs, ma le note prodotte erano pi\`u esatte, proprio per la capacit\`a di tenere in considerazione la storia delle note (cosa che la FFN non fa), pi\`u varie rispetto alla rete neurale non ricorrente che cercava di riprodurre il brano usato per il train ma nient'altro di pi\`u.\\
Il primo brano preso in esame \`e \emph{Fly Me To The Moon}, il secondo invece \`e \emph{Kathy's Song}.
\\Gli errori di train e validazione sono stati:
\begin{table}[ht]
\centering
\begin{tabular}{ c  c }
    \begin{tabular}{| c | c | c |}
    \multicolumn {3}{c}{\textbf{Errori primo brano}}\\
    \hline
    &\textbf{FFN}&\textbf{RNN}\\\hline
    Allenamento&0.580332&0.058844\\\hline
    Validazione&1.387929&0.892960\\\hline
    \end{tabular}
    &
    \begin{tabular}{| c | c | c |}
    \multicolumn {3}{c}{\textbf{Errori secondo brano}}\\
    \hline
    &\textbf{FFN}&\textbf{RNN}\\\hline
    Allenamento&1.745513&0.032295\\\hline
    Validazione&1.740951&0.985849\\\hline
    \end{tabular}\\
\end{tabular}
\end{table}
\\Questa volta sono riportati, per sinteticit\`a, glli errori medi in fase di allenamento e validazione. Si pu\`o vedere chiaramente che la FFN non riesce ad imparare bene le canzoni, infatti i suoi errori sono pi\`u alti se confrontati con quelli della RNN.

\begin{table}[h!t]
\centering
\begin{tabular}{| c | c |}
\multicolumn {2}{c}{\textbf{Errori medi primo brano}}\\
\hline
\textbf{FFN}&\textbf{RNN}\\\hline
\includegraphics[width=0.4\textwidth]{img/ffn_fly_errors.png}
&
\includegraphics[width=0.4\textwidth]{img/rnn_fly_errors.png}
\\\hline
\end{tabular}
\end{table}

\begin{table}[h!t]
\centering
\begin{tabular}{| c | c |}
\multicolumn {2}{c}{\textbf{Errori medi secondo brano}}\\
\hline
\textbf{FFN}&\textbf{RNN}\\\hline
\includegraphics[width=0.4\textwidth]{img/ffn_kathy_errors.png}
&
\includegraphics[width=0.4\textwidth]{img/rnn_kathy_errors.png}
\\\hline
\end{tabular}
\end{table}
\newpage
\subsection{Esperimento 3 - Imparare pi\`u di una canzone}
Quando si \`e trattato di far imparare alle reti pi\`u di una canzone sono sorti alcuni problemi perch\`e queste in qualche modo dimenticavano le sequenze gi\`a imparate a favore delle ultime viste; inoltre si riscontravano problemi a livello del codice utilizzato per implementare le reti~\cite{schaul2010pybrain} che non si \`e riusciti ad identificare ma evidentemente presenti visto l'andamento degli errori di train e validazione.
\begin{table}[h!t]
\centering
\begin{tabular}{| c | c |}
\multicolumn {2}{c}{\textbf{Errori RNN su pi\`u canzoni}}\\
\hline
\textbf{Tutti gli errori}&\textbf{Errori medi k-fold}\\\hline
\includegraphics[width=0.4\textwidth]{img/rnn_songs_all_errors.png}
&
\includegraphics[width=0.4\textwidth]{img/rnn_songs_kfold_errors.png}
\\\hline
\end{tabular}
\end{table}
\newpage
\begin{table}[h!t]
\centering
\begin{tabular}{| c | c |}
\multicolumn {2}{c}{\textbf{Errori FFN}}\\
\hline
\textbf{Tutti gli errori}&\textbf{Errori medi k-fold}\\\hline
\includegraphics[width=0.4\textwidth]{img/ffn_songs_all_errors.png}
&
\includegraphics[width=0.4\textwidth]{img/ffn_songs_kfold_errors.png}
\\\hline
\end{tabular}
\end{table}
Come si pu\`o vedere dai primi grafici l'andamento degli errori non ha il comportamento che ci si aspetta da una rete. Se si valutano gli errori medi si evince un andamento pi\`u classico ma guardando quelli per ogni sessione si vede che non \`e normale e, purtroppo, non \`e stato trovato un motivo a questo andamento.\\
\newpage